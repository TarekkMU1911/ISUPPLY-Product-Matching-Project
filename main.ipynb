{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the train DataSet that contains at least : seller_item_name , price and sku columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>marketplace_product_name_ar</th>\n",
       "      <th>seller_item_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>ESTOHALT 40 MG 14 CAP</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sku marketplace_product_name_ar       seller_item_name  price\n",
       "0  1322    استوهالت 40 مجم 14 كبسول  ESTOHALT 40 MG 14 CAP   56.5\n",
       "1  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "2  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "3  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "4  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the filename with the name of the file you want to train\n",
    "df = pd.read_excel(\"Product Matching Dataset.xlsx\" , sheet_name=\"Dataset\")  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83562, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83562 entries, 0 to 83561\n",
      "Data columns (total 4 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   sku                          83562 non-null  int64  \n",
      " 1   marketplace_product_name_ar  83562 non-null  object \n",
      " 2   seller_item_name             83562 non-null  object \n",
      " 3   price                        83562 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83562.000000</td>\n",
       "      <td>83562.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1600.653204</td>\n",
       "      <td>79.055458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1469.206223</td>\n",
       "      <td>62.818117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1312.000000</td>\n",
       "      <td>61.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2258.000000</td>\n",
       "      <td>100.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9532.000000</td>\n",
       "      <td>406.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sku         price\n",
       "count  83562.000000  83562.000000\n",
       "mean    1600.653204     79.055458\n",
       "std     1469.206223     62.818117\n",
       "min        4.000000      7.000000\n",
       "25%      476.000000     38.000000\n",
       "50%     1312.000000     61.500000\n",
       "75%     2258.000000    100.500000\n",
       "max     9532.000000    406.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                            0\n",
       "marketplace_product_name_ar    0\n",
       "seller_item_name               0\n",
       "price                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffling the Taining Dataset to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'marketplace_product_name_ar', 'seller_item_name', 'price'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (66849, 4)\n",
      "Test DataFrame shape: (16713, 4)\n",
      "\n",
      "Train DataFrame first rows:\n",
      "     sku marketplace_product_name_ar          seller_item_name  price\n",
      "0  1312      موزابرايد 5 مجم 30 قرص   موزابريد 5مج س ج ويسترن   91.5\n",
      "1  4743     ميكروسيرك 16 مجم 20 قرص  ميكروسيرك16مل ق/العامرية   29.0\n",
      "2  2517  البافيت كالسيوم شراب 60 مل      البافيت شراب كالسيوم   26.0\n",
      "3  2374     زيستريل 20 مجم 10 اقراص   زيستريل 20 مجم سعر جديد   52.0\n",
      "4   639           اتور 10 مجم 7 قرص         اتور 10 مجم اقراص   33.0\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=40).reset_index(drop=True)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['sku'], random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Train DataFrame shape:\", train_df.shape)\n",
    "print(\"Test DataFrame shape:\", val_df.shape)\n",
    "print(\"\\nTrain DataFrame first rows:\\n\", train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing text Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/qc/_v6f30pj3sq1vn0jhkyg29zw0000gn/T/ipykernel_60001/581496695.py:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  pattern = '[^\\u0621-\\u064A0-9a-zA-Z\\s]'\n"
     ]
    }
   ],
   "source": [
    "def word_preprocessing(text):\n",
    "    nltk.download('stopwords')\n",
    "    arabic_stopwords = set(stopwords.words('arabic'))\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    X = []\n",
    "    for i in range(len(text)):\n",
    "        statement = text[i].lower()\n",
    "        \n",
    "        statement = re.sub(r'[إأآ]', 'ا', statement)  \n",
    "        statement = re.sub(r'ى', 'ي', statement)  \n",
    "        statement = re.sub(r'ة', 'ه', statement)  \n",
    "        statement = re.sub(r'ؤ', 'و', statement)  \n",
    "        statement = re.sub(r'ئ', 'ي', statement)  \n",
    "        statement = re.sub(r'ــ', '', statement)\n",
    "        \n",
    "        statement = re.sub(r'([\\u0600-\\u06FF])\\1', r'\\1', statement)\n",
    "        \n",
    "        statement = re.sub(r'(\\d+)(?=\\D)', r'\\1 ', statement)\n",
    "        statement = re.sub(r'(\\D)(\\d+)', r'\\1 \\2', statement)\n",
    "        \n",
    "        pattern = '[^\\u0621-\\u064A0-9a-zA-Z\\s]' \n",
    "        statement = re.sub(pattern, ' ', statement)\n",
    "        \n",
    "        pattern = r\"(?<!\\d)(.)\\1+(?!\\d)\"\n",
    "        statement = re.sub(pattern, r\"\\1\", statement)\n",
    "        \n",
    "        pattern = r'\\b(مل|ملي|مم|جم|مج|مجم|عادي|عاده)\\b'\n",
    "        statement =  re.sub(pattern, '', statement)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pattern = r'\\b(اقراص\\w*|قرص\\w*|شري\\w*|كبسول\\w*|شرايط|افلام|فيلم|استحلاب|ك|ق)\\b'\n",
    "        statement =  re.sub(pattern, 'قرص', statement)\n",
    "        \n",
    "        pattern = r'\\bقرص\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'قرص ', statement)        \n",
    "    \n",
    "        pattern = r'\\bامبول\\w*|حقن\\w*\\b'\n",
    "        statement = re.sub(pattern, 'امبول', statement)\n",
    "        \n",
    "        pattern = r'\\bامبول\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'امبول', statement)\n",
    "        \n",
    "        pattern = r'جل'\n",
    "        statement = re.sub(pattern, 'جيل', statement)\n",
    "        \n",
    "        pattern = r'\\bجيل\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'جيل', statement)\n",
    "        \n",
    "        pattern = r'جيل.*غسول'\n",
    "        statement = re.sub(pattern, 'غسول', statement)\n",
    "        \n",
    "        pattern = r'\\bغسول\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'غسول', statement)\n",
    "        \n",
    "        pattern = r'\\bمحلول\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'محلول', statement)\n",
    "        \n",
    "        pattern = r'\\bلبوس\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'لبوس', statement)\n",
    "        \n",
    "        \n",
    "        pattern = r'قطر\\D+'\n",
    "        statement = re.sub(pattern, r'نقط', statement)\n",
    "        \n",
    "        pattern = r'\\b(قطره|قطر|نقط|نقطه|قطرهعين)\\b'\n",
    "        statement =  re.sub(pattern, 'نقط', statement)\n",
    "        \n",
    "        pattern = r'\\bنقط\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'نقط', statement)\n",
    "        \n",
    "        pattern = r'\\sاكياس|اكيااس'\n",
    "        statement = re.sub(pattern, 'كيس', statement)\n",
    "        \n",
    "        pattern = r'\\bكيس\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'كيس', statement)\n",
    "        \n",
    "        pattern = r'\\b(سبراي|بخاخه)\\b'\n",
    "        statement =  re.sub(pattern, 'بخاخ', statement)\n",
    "        \n",
    "        pattern = r'\\bبخاخ\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'بخاخ', statement)\n",
    "        \n",
    "        pattern = r'مرهم|اكريم'\n",
    "        statement = re.sub(pattern, 'كريم', statement)\n",
    "        \n",
    "        pattern = r'\\bكريم\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'كريم', statement)\n",
    "        \n",
    "        pattern = r'\\b\\w*استنشاق\\w*\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'استنشـاق'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'شـراب+|شرب+|شراب+'\n",
    "        statement = re.sub(pattern, ' شراب', statement)\n",
    "        \n",
    "        pattern = r'\\bشراب\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'شراب', statement)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pattern = r'\\b[قديم]+\\b' \n",
    "        statement = re.sub(pattern, '', statement)\n",
    "\n",
    "        pattern = r'\\b[جديد]+\\b'\n",
    "        statement = re.sub(pattern,\"\", statement)\n",
    "        \n",
    "        pattern = r'\\b[ء-ي]\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\b[سعر]+\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\bسج|سق\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\b\\w*سعر\\w*\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\b\\w*جدي\\w*\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        statement = re.sub('mg', '', statement)\n",
    "        \n",
    "        words = statement.split()\n",
    "        filtered_words = [word for word in words if word not in arabic_stopwords and word not in english_stopwords]\n",
    "\n",
    "        X.append(' '.join(filtered_words))\n",
    "   \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_train_df(train_df):\n",
    "    seller_name = train_df['seller_item_name'].apply(str)\n",
    "    X_train_text = word_preprocessing(seller_name)\n",
    "    X_train_text = cv.fit_transform(X_train_text).toarray()\n",
    "\n",
    "    X_train_price = train_df[['price']].values  \n",
    "    X_train_price = StandardScaler().fit_transform(X_train_price)  \n",
    "\n",
    "    X_train_combined = np.hstack([X_train_text, X_train_price])  \n",
    "\n",
    "    y_train = train_df['sku'].values\n",
    "    y_train = le.fit_transform(y_train)\n",
    "\n",
    "    return X_train_combined, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_val_test_df(df):\n",
    "    seller_name = df['seller_item_name'].apply(str)\n",
    "    X_test_text = word_preprocessing(seller_name)\n",
    "    X_test_text = cv.transform(X_test_text).toarray()  \n",
    "\n",
    "    X_test_price = df[['price']].values  \n",
    "    X_test_price = StandardScaler().fit_transform(X_test_price)  \n",
    "\n",
    "    X_test_combined = np.hstack([X_test_text, X_test_price])  \n",
    "\n",
    "    y_test = df['sku'].values\n",
    "    y_test = le.transform(y_test)\n",
    "\n",
    "    return X_test_combined, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_notmatched_df(df):\n",
    "    seller_name = df['seller_item_name'].apply(str)\n",
    "    X_test_text = word_preprocessing(seller_name)\n",
    "    X_test_text = cv.transform(X_test_text).toarray()  \n",
    "\n",
    "    X_test_price = df[['price']].values  \n",
    "    X_test_price = StandardScaler().fit_transform(X_test_price)  \n",
    "\n",
    "    X_test_combined = np.hstack([X_test_text, X_test_price])  \n",
    "\n",
    "\n",
    "    return X_test_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preparing_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val  = preparing_val_test_df(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66849"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.5211 - loss: 3.8106 - val_accuracy: 0.9628 - val_loss: 0.9793 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9668 - loss: 0.3414 - val_accuracy: 0.9780 - val_loss: 0.1579 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.1695 - val_accuracy: 0.9808 - val_loss: 0.1336 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9872 - loss: 0.1260 - val_accuracy: 0.9832 - val_loss: 0.1232 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9880 - loss: 0.1085 - val_accuracy: 0.9882 - val_loss: 0.1126 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9902 - loss: 0.0945 - val_accuracy: 0.9879 - val_loss: 0.1053 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9907 - loss: 0.0866 - val_accuracy: 0.9865 - val_loss: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9927 - loss: 0.0801 - val_accuracy: 0.9892 - val_loss: 0.0976 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9921 - loss: 0.0765 - val_accuracy: 0.9874 - val_loss: 0.0990 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9926 - loss: 0.0734 - val_accuracy: 0.9886 - val_loss: 0.0967 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9929 - loss: 0.0712 - val_accuracy: 0.9895 - val_loss: 0.0942 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0735 - val_accuracy: 0.9899 - val_loss: 0.0916 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9931 - loss: 0.0664 - val_accuracy: 0.9882 - val_loss: 0.0957 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9926 - loss: 0.0668 - val_accuracy: 0.9889 - val_loss: 0.0902 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9925 - loss: 0.0656 - val_accuracy: 0.9898 - val_loss: 0.0949 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9931 - loss: 0.0683 - val_accuracy: 0.9887 - val_loss: 0.0936 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9939 - loss: 0.0610\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9939 - loss: 0.0610 - val_accuracy: 0.9877 - val_loss: 0.0955 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9956 - loss: 0.0562 - val_accuracy: 0.9903 - val_loss: 0.0816 - learning_rate: 2.5000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9947 - loss: 0.0505 - val_accuracy: 0.9907 - val_loss: 0.0788 - learning_rate: 2.5000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9957 - loss: 0.0455 - val_accuracy: 0.9908 - val_loss: 0.0766 - learning_rate: 2.5000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9957 - loss: 0.0429 - val_accuracy: 0.9902 - val_loss: 0.0752 - learning_rate: 2.5000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9955 - loss: 0.0422 - val_accuracy: 0.9907 - val_loss: 0.0713 - learning_rate: 2.5000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9956 - loss: 0.0403 - val_accuracy: 0.9899 - val_loss: 0.0733 - learning_rate: 2.5000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9958 - loss: 0.0393 - val_accuracy: 0.9902 - val_loss: 0.0686 - learning_rate: 2.5000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9954 - loss: 0.0375 - val_accuracy: 0.9891 - val_loss: 0.0726 - learning_rate: 2.5000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9953 - loss: 0.0372 - val_accuracy: 0.9893 - val_loss: 0.0716 - learning_rate: 2.5000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9953 - loss: 0.0361 - val_accuracy: 0.9907 - val_loss: 0.0675 - learning_rate: 2.5000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9953 - loss: 0.0359 - val_accuracy: 0.9905 - val_loss: 0.0667 - learning_rate: 2.5000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9958 - loss: 0.0330 - val_accuracy: 0.9908 - val_loss: 0.0667 - learning_rate: 2.5000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9955 - loss: 0.0344 - val_accuracy: 0.9905 - val_loss: 0.0671 - learning_rate: 2.5000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9954 - loss: 0.0342 - val_accuracy: 0.9903 - val_loss: 0.0655 - learning_rate: 2.5000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9963 - loss: 0.0315 - val_accuracy: 0.9903 - val_loss: 0.0671 - learning_rate: 2.5000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9961 - loss: 0.0319 - val_accuracy: 0.9910 - val_loss: 0.0661 - learning_rate: 2.5000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m521/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9956 - loss: 0.0321\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9956 - loss: 0.0321 - val_accuracy: 0.9904 - val_loss: 0.0674 - learning_rate: 2.5000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9962 - loss: 0.0305 - val_accuracy: 0.9910 - val_loss: 0.0644 - learning_rate: 1.2500e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9968 - loss: 0.0271 - val_accuracy: 0.9914 - val_loss: 0.0626 - learning_rate: 1.2500e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9969 - loss: 0.0261 - val_accuracy: 0.9913 - val_loss: 0.0624 - learning_rate: 1.2500e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9961 - loss: 0.0257 - val_accuracy: 0.9911 - val_loss: 0.0601 - learning_rate: 1.2500e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9965 - loss: 0.0241 - val_accuracy: 0.9910 - val_loss: 0.0618 - learning_rate: 1.2500e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9967 - loss: 0.0228 - val_accuracy: 0.9915 - val_loss: 0.0597 - learning_rate: 1.2500e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9964 - loss: 0.0230 - val_accuracy: 0.9911 - val_loss: 0.0607 - learning_rate: 1.2500e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0217 - val_accuracy: 0.9913 - val_loss: 0.0597 - learning_rate: 1.2500e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9967 - loss: 0.0216 - val_accuracy: 0.9915 - val_loss: 0.0569 - learning_rate: 1.2500e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9967 - loss: 0.0210 - val_accuracy: 0.9917 - val_loss: 0.0568 - learning_rate: 1.2500e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9966 - loss: 0.0209 - val_accuracy: 0.9909 - val_loss: 0.0566 - learning_rate: 1.2500e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0210 - val_accuracy: 0.9922 - val_loss: 0.0550 - learning_rate: 1.2500e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9970 - loss: 0.0194 - val_accuracy: 0.9916 - val_loss: 0.0582 - learning_rate: 1.2500e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9964 - loss: 0.0204 - val_accuracy: 0.9914 - val_loss: 0.0580 - learning_rate: 1.2500e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9967 - loss: 0.0200\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9967 - loss: 0.0200 - val_accuracy: 0.9914 - val_loss: 0.0581 - learning_rate: 1.2500e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9970 - loss: 0.0191 - val_accuracy: 0.9924 - val_loss: 0.0549 - learning_rate: 6.2500e-05\n",
      "Epoch 51/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9972 - loss: 0.0178 - val_accuracy: 0.9919 - val_loss: 0.0553 - learning_rate: 6.2500e-05\n",
      "Epoch 52/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0174 - val_accuracy: 0.9923 - val_loss: 0.0545 - learning_rate: 6.2500e-05\n",
      "Epoch 53/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0163 - val_accuracy: 0.9915 - val_loss: 0.0544 - learning_rate: 6.2500e-05\n",
      "Epoch 54/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9968 - loss: 0.0164 - val_accuracy: 0.9919 - val_loss: 0.0548 - learning_rate: 6.2500e-05\n",
      "Epoch 55/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9977 - loss: 0.0151 - val_accuracy: 0.9920 - val_loss: 0.0543 - learning_rate: 6.2500e-05\n",
      "Epoch 56/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9969 - loss: 0.0158 - val_accuracy: 0.9917 - val_loss: 0.0544 - learning_rate: 6.2500e-05\n",
      "Epoch 57/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9973 - loss: 0.0156 - val_accuracy: 0.9921 - val_loss: 0.0541 - learning_rate: 6.2500e-05\n",
      "Epoch 58/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9970 - loss: 0.0154 - val_accuracy: 0.9919 - val_loss: 0.0525 - learning_rate: 6.2500e-05\n",
      "Epoch 59/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9971 - loss: 0.0146 - val_accuracy: 0.9915 - val_loss: 0.0523 - learning_rate: 6.2500e-05\n",
      "Epoch 60/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9972 - loss: 0.0146 - val_accuracy: 0.9915 - val_loss: 0.0535 - learning_rate: 6.2500e-05\n",
      "Epoch 61/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9968 - loss: 0.0151 - val_accuracy: 0.9920 - val_loss: 0.0526 - learning_rate: 6.2500e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9976 - loss: 0.0142\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0142 - val_accuracy: 0.9920 - val_loss: 0.0531 - learning_rate: 6.2500e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9970 - loss: 0.0145 - val_accuracy: 0.9923 - val_loss: 0.0525 - learning_rate: 3.1250e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9973 - loss: 0.0138 - val_accuracy: 0.9920 - val_loss: 0.0532 - learning_rate: 3.1250e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9974 - loss: 0.0136\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0136 - val_accuracy: 0.9919 - val_loss: 0.0523 - learning_rate: 3.1250e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9972 - loss: 0.0134 - val_accuracy: 0.9920 - val_loss: 0.0525 - learning_rate: 1.5625e-05\n",
      "Epoch 67/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0127 - val_accuracy: 0.9923 - val_loss: 0.0524 - learning_rate: 1.5625e-05\n",
      "Epoch 68/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0135 - val_accuracy: 0.9922 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
      "Epoch 69/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0128 - val_accuracy: 0.9923 - val_loss: 0.0515 - learning_rate: 1.5625e-05\n",
      "Epoch 70/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0128 - val_accuracy: 0.9922 - val_loss: 0.0519 - learning_rate: 1.5625e-05\n",
      "Epoch 71/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0125 - val_accuracy: 0.9923 - val_loss: 0.0518 - learning_rate: 1.5625e-05\n",
      "Epoch 72/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9972 - loss: 0.0125 - val_accuracy: 0.9922 - val_loss: 0.0514 - learning_rate: 1.5625e-05\n",
      "Epoch 73/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0121 - val_accuracy: 0.9926 - val_loss: 0.0515 - learning_rate: 1.5625e-05\n",
      "Epoch 74/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9969 - loss: 0.0133 - val_accuracy: 0.9922 - val_loss: 0.0515 - learning_rate: 1.5625e-05\n",
      "Epoch 75/150\n",
      "\u001b[1m521/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9972 - loss: 0.0129\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9972 - loss: 0.0129 - val_accuracy: 0.9926 - val_loss: 0.0513 - learning_rate: 1.5625e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0121 - val_accuracy: 0.9927 - val_loss: 0.0513 - learning_rate: 7.8125e-06\n",
      "Epoch 77/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0121 - val_accuracy: 0.9925 - val_loss: 0.0511 - learning_rate: 7.8125e-06\n",
      "Epoch 78/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9969 - loss: 0.0126 - val_accuracy: 0.9923 - val_loss: 0.0511 - learning_rate: 7.8125e-06\n",
      "Epoch 79/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9973 - loss: 0.0120 - val_accuracy: 0.9926 - val_loss: 0.0513 - learning_rate: 7.8125e-06\n",
      "Epoch 80/150\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9975 - loss: 0.0120\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0120 - val_accuracy: 0.9924 - val_loss: 0.0512 - learning_rate: 7.8125e-06\n",
      "Epoch 81/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9972 - loss: 0.0121 - val_accuracy: 0.9926 - val_loss: 0.0511 - learning_rate: 3.9063e-06\n",
      "Epoch 82/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9977 - loss: 0.0121 - val_accuracy: 0.9926 - val_loss: 0.0514 - learning_rate: 3.9063e-06\n",
      "Epoch 83/150\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9977 - loss: 0.0114\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9977 - loss: 0.0114 - val_accuracy: 0.9926 - val_loss: 0.0514 - learning_rate: 3.9063e-06\n",
      "Epoch 84/150\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0116 - val_accuracy: 0.9926 - val_loss: 0.0514 - learning_rate: 1.9531e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3094e8620>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(set(y_train))  \n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001), input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.01)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=128, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0110\n",
      "Train Accuracy: 0.9979\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0520\n",
      "Validation Accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_score(X_test, y_test):\n",
    "    probabilities = model.predict(X_test)\n",
    "\n",
    "    confidence_scores = np.max(probabilities, axis=1)\n",
    "\n",
    "    predicted_indices = np.argmax(probabilities, axis=1)\n",
    "\n",
    "    predicted_labels = le.inverse_transform(predicted_indices)\n",
    "\n",
    "    true_labels = le.inverse_transform(y_test)\n",
    "\n",
    "    confidence_threshold = 0.9\n",
    "\n",
    "    test_results = []\n",
    "    incorrect_count = 0\n",
    "    high_confidence_count = 0\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        confidence = confidence_scores[i]\n",
    "        predicted_class = predicted_labels[i]\n",
    "        true_class = true_labels[i]\n",
    "\n",
    "        \n",
    "        if confidence > confidence_threshold:\n",
    "            high_confidence_count += 1  \n",
    "            if predicted_class != true_class:\n",
    "                incorrect_count += 1  \n",
    "\n",
    "        if confidence < confidence_threshold:\n",
    "            predicted_class = \"Unknown\"\n",
    "\n",
    "        test_results.append({\n",
    "            'Predicted': predicted_class\n",
    "        })\n",
    "        \n",
    "    if high_confidence_count > 0:\n",
    "        error_percentage = (incorrect_count / high_confidence_count) * 100\n",
    "    else:\n",
    "        error_percentage = 0.0\n",
    "        \n",
    "\n",
    "    temp_df = pd.DataFrame(test_results)\n",
    "    print(f\"Percentage of incorrect classifications with confidence > 0.9: {error_percentage:.2f}%\")\n",
    "    print(temp_df.head())\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Percentage of incorrect classifications with confidence > 0.9: 0.17%\n",
      "  Predicted\n",
      "0       277\n",
      "1      1795\n",
      "2      1367\n",
      "3      1738\n",
      "4      2529\n"
     ]
    }
   ],
   "source": [
    "temp_df = confidence_score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>marketplace_product_name_ar</th>\n",
       "      <th>seller_item_name</th>\n",
       "      <th>price</th>\n",
       "      <th>Predicted_sku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277</td>\n",
       "      <td>هاي فريش 0.2 % قطرة عين 10 مل</td>\n",
       "      <td>هاى فريش</td>\n",
       "      <td>75.0</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1795</td>\n",
       "      <td>اوكيوجارد 30 كبسول</td>\n",
       "      <td>اوكيوجارد 30كبسوله</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1367</td>\n",
       "      <td>انتيكوكس 15 مجم 30 قرص</td>\n",
       "      <td>انتي كوكس اا 15 30قرص س.ج #</td>\n",
       "      <td>73.5</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1738</td>\n",
       "      <td>كو افازير قطرة عين 10 مل</td>\n",
       "      <td>كو افازير قطرة</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2529</td>\n",
       "      <td>كاردورا 1 مجم 21 قرص</td>\n",
       "      <td>كاردورا  1 مجم  اقراص</td>\n",
       "      <td>58.5</td>\n",
       "      <td>2529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sku    marketplace_product_name_ar             seller_item_name  price  \\\n",
       "0   277  هاي فريش 0.2 % قطرة عين 10 مل                    هاى فريش    75.0   \n",
       "1  1795             اوكيوجارد 30 كبسول           اوكيوجارد 30كبسوله  120.0   \n",
       "2  1367         انتيكوكس 15 مجم 30 قرص  انتي كوكس اا 15 30قرص س.ج #   73.5   \n",
       "3  1738       كو افازير قطرة عين 10 مل              كو افازير قطرة    29.0   \n",
       "4  2529           كاردورا 1 مجم 21 قرص        كاردورا  1 مجم  اقراص   58.5   \n",
       "\n",
       "  Predicted_sku  \n",
       "0           277  \n",
       "1          1795  \n",
       "2          1367  \n",
       "3          1738  \n",
       "4          2529  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df['Predicted_sku'] = temp_df['Predicted']\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.to_csv('val_prediction.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to make model predictions on another test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### please enter its path between the practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>marketplace_product_name_ar</th>\n",
       "      <th>seller_item_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>ESTOHALT 40 MG 14 CAP</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sku marketplace_product_name_ar       seller_item_name  price\n",
       "0  1322    استوهالت 40 مجم 14 كبسول  ESTOHALT 40 MG 14 CAP   56.5\n",
       "1  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "2  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "3  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "4  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the filename with the name of the file you want to test\n",
    "test_df = pd.read_excel(\"Product Matching Dataset.xlsx\" , sheet_name=\"Dataset\")  \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "X_test , y_test = preparing_val_test_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2612/2612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n",
      "Percentage of incorrect classifications with confidence > 0.9: 0.04%\n",
      "  Predicted\n",
      "0      1322\n",
      "1      1322\n",
      "2      1322\n",
      "3      1322\n",
      "4      1322\n"
     ]
    }
   ],
   "source": [
    "temp_df_2 = confidence_score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Predicted_sku'] = temp_df_2['Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test_prediction.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
