{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the train DataSet that contains at least : seller_item_name , price and sku columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>marketplace_product_name_ar</th>\n",
       "      <th>seller_item_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>ESTOHALT 40 MG 14 CAP</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sku marketplace_product_name_ar       seller_item_name  price\n",
       "0  1322    استوهالت 40 مجم 14 كبسول  ESTOHALT 40 MG 14 CAP   56.5\n",
       "1  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "2  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "3  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "4  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the filename with the name of the file you want to train\n",
    "df = pd.read_excel(\"Product Matching Dataset.xlsx\" , sheet_name=\"Dataset\")  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the test DataSet that contains at least : seller_item_name column & price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>marketplace_product_name_ar</th>\n",
       "      <th>seller_item_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>ESTOHALT 40 MG 14 CAP</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1322</td>\n",
       "      <td>استوهالت 40 مجم 14 كبسول</td>\n",
       "      <td>استوهالت 40 مجم 14 ك</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sku marketplace_product_name_ar       seller_item_name  price\n",
       "0  1322    استوهالت 40 مجم 14 كبسول  ESTOHALT 40 MG 14 CAP   56.5\n",
       "1  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "2  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "3  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5\n",
       "4  1322    استوهالت 40 مجم 14 كبسول   استوهالت 40 مجم 14 ك   56.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the filename with the name of the file you want to test\n",
    "test_df = pd.read_csv('test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83562, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83562 entries, 0 to 83561\n",
      "Data columns (total 4 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   sku                          83562 non-null  int64  \n",
      " 1   marketplace_product_name_ar  83562 non-null  object \n",
      " 2   seller_item_name             83562 non-null  object \n",
      " 3   price                        83562 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83562.000000</td>\n",
       "      <td>83562.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1600.653204</td>\n",
       "      <td>79.055458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1469.206223</td>\n",
       "      <td>62.818117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1312.000000</td>\n",
       "      <td>61.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2258.000000</td>\n",
       "      <td>100.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9532.000000</td>\n",
       "      <td>406.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sku         price\n",
       "count  83562.000000  83562.000000\n",
       "mean    1600.653204     79.055458\n",
       "std     1469.206223     62.818117\n",
       "min        4.000000      7.000000\n",
       "25%      476.000000     38.000000\n",
       "50%     1312.000000     61.500000\n",
       "75%     2258.000000    100.500000\n",
       "max     9532.000000    406.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                            0\n",
       "marketplace_product_name_ar    0\n",
       "seller_item_name               0\n",
       "price                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffling the Taining Dataset to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'marketplace_product_name_ar', 'seller_item_name', 'price'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (66849, 4)\n",
      "Test DataFrame shape: (16713, 4)\n",
      "\n",
      "Train DataFrame first rows:\n",
      "     sku marketplace_product_name_ar        seller_item_name  price\n",
      "0  1312      موزابرايد 5 مجم 30 قرص  موزابرايد 5 مجم 30 قرص   91.5\n",
      "1  4743     ميكروسيرك 16 مجم 20 قرص   ميكروسيرك 16مجم اقراص   29.0\n",
      "2  2517  البافيت كالسيوم شراب 60 مل    البافيت كالسيوم شراب   26.0\n",
      "3  2374     زيستريل 20 مجم 10 اقراص     زيستريل 20مجم اقراص   52.0\n",
      "4   639           اتور 10 مجم 7 قرص    اتور 10مجم جدييييييد   33.0\n"
     ]
    }
   ],
   "source": [
    "train_df, validation_df = train_test_split(df, test_size=0.2, stratify=df['sku'], random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Train DataFrame shape:\", train_df.shape)\n",
    "print(\"Test DataFrame shape:\", validation_df.shape)\n",
    "print(\"\\nTrain DataFrame first rows:\\n\", train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing text Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/qc/_v6f30pj3sq1vn0jhkyg29zw0000gn/T/ipykernel_14577/3685696276.py:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  pattern = '[^\\u0621-\\u064A0-9a-zA-Z\\s]'\n"
     ]
    }
   ],
   "source": [
    "def word_preprocessing(text):\n",
    "    nltk.download('stopwords')\n",
    "    arabic_stopwords = set(stopwords.words('arabic'))\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    X = []\n",
    "    for i in range(len(text)):\n",
    "        statement = text[i].lower()\n",
    "        \n",
    "        statement = re.sub(r'[إأآ]', 'ا', statement)  \n",
    "        statement = re.sub(r'ى', 'ي', statement)  \n",
    "        statement = re.sub(r'ة', 'ه', statement)  \n",
    "        statement = re.sub(r'ؤ', 'و', statement)  \n",
    "        statement = re.sub(r'ئ', 'ي', statement)  \n",
    "        statement = re.sub(r'ــ', '', statement)\n",
    "        \n",
    "        statement = re.sub(r'([\\u0600-\\u06FF])\\1', r'\\1', statement)\n",
    "        \n",
    "        statement = re.sub(r'(\\d+)(?=\\D)', r'\\1 ', statement)\n",
    "        statement = re.sub(r'(\\D)(\\d+)', r'\\1 \\2', statement)\n",
    "        \n",
    "        pattern = '[^\\u0621-\\u064A0-9a-zA-Z\\s]' \n",
    "        statement = re.sub(pattern, ' ', statement)\n",
    "        \n",
    "        pattern = r\"(?<!\\d)(.)\\1+(?!\\d)\"\n",
    "        statement = re.sub(pattern, r\"\\1\", statement)\n",
    "        \n",
    "        pattern = r'\\b(مل|ملي|مم|جم|مج|مجم|عادي|عاده)\\b'\n",
    "        statement =  re.sub(pattern, '', statement)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pattern = r'\\b(اقراص\\w*|قرص\\w*|شري\\w*|كبسول\\w*|شرايط|افلام|فيلم|استحلاب|ك|ق)\\b'\n",
    "        statement =  re.sub(pattern, 'قرص', statement)\n",
    "        \n",
    "        pattern = r'\\bقرص\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'قرص ', statement)        \n",
    "    \n",
    "        pattern = r'\\bامبول\\w*|حقن\\w*\\b'\n",
    "        statement = re.sub(pattern, 'امبول', statement)\n",
    "        \n",
    "        pattern = r'\\bامبول\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'امبول', statement)\n",
    "        \n",
    "        pattern = r'جل'\n",
    "        statement = re.sub(pattern, 'جيل', statement)\n",
    "        \n",
    "        pattern = r'\\bجيل\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'جيل', statement)\n",
    "        \n",
    "        pattern = r'جيل.*غسول'\n",
    "        statement = re.sub(pattern, 'غسول', statement)\n",
    "        \n",
    "        pattern = r'\\bغسول\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'غسول', statement)\n",
    "        \n",
    "        pattern = r'\\bمحلول\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'محلول', statement)\n",
    "        \n",
    "        pattern = r'\\bلبوس\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'لبوس', statement)\n",
    "        \n",
    "        \n",
    "        pattern = r'قطر\\D+'\n",
    "        statement = re.sub(pattern, r'نقط', statement)\n",
    "        \n",
    "        pattern = r'\\b(قطره|قطر|نقط|نقطه|قطرهعين)\\b'\n",
    "        statement =  re.sub(pattern, 'نقط', statement)\n",
    "        \n",
    "        pattern = r'\\bنقط\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'نقط', statement)\n",
    "        \n",
    "        pattern = r'\\sاكياس|اكيااس'\n",
    "        statement = re.sub(pattern, 'كيس', statement)\n",
    "        \n",
    "        pattern = r'\\bكيس\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'كيس', statement)\n",
    "        \n",
    "        pattern = r'\\b(سبراي|بخاخه)\\b'\n",
    "        statement =  re.sub(pattern, 'بخاخ', statement)\n",
    "        \n",
    "        pattern = r'\\bبخاخ\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'بخاخ', statement)\n",
    "        \n",
    "        pattern = r'مرهم|اكريم'\n",
    "        statement = re.sub(pattern, 'كريم', statement)\n",
    "        \n",
    "        pattern = r'\\bكريم\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'كريم', statement)\n",
    "        \n",
    "        pattern = r'\\b\\w*استنشاق\\w*\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'استنشـاق'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'شـراب+|شرب+|شراب+'\n",
    "        statement = re.sub(pattern, ' شراب', statement)\n",
    "        \n",
    "        pattern = r'\\bشراب\\s+([^0-9\\s]+)\\s*'\n",
    "        statement = re.sub(pattern, 'شراب', statement)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pattern = r'\\b[قديم]+\\b' \n",
    "        statement = re.sub(pattern, '', statement)\n",
    "\n",
    "        pattern = r'\\b[جديد]+\\b'\n",
    "        statement = re.sub(pattern,\"\", statement)\n",
    "        \n",
    "        pattern = r'\\b[ء-ي]\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\b[سعر]+\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\bسج|سق\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\b\\w*سعر\\w*\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        pattern = r'\\b\\w*جدي\\w*\\b'\n",
    "        statement = re.sub(pattern, '', statement)\n",
    "        \n",
    "        statement = re.sub('mg', '', statement)\n",
    "        \n",
    "        words = statement.split()\n",
    "        filtered_words = [word for word in words if word not in arabic_stopwords and word not in english_stopwords]\n",
    "\n",
    "        X.append(' '.join(filtered_words))\n",
    "   \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_train_df(train_df):\n",
    "    seller_name = train_df['seller_item_name'].apply(str)\n",
    "    X_train_text = word_preprocessing(seller_name)\n",
    "    X_train_text = cv.fit_transform(X_train_text).toarray()\n",
    "\n",
    "    X_train_price = train_df[['price']].values  \n",
    "    X_train_price = StandardScaler().fit_transform(X_train_price)  \n",
    "\n",
    "    X_train_combined = np.hstack([X_train_text, X_train_price])  \n",
    "\n",
    "    y_train = train_df['sku'].values\n",
    "    y_train = le.fit_transform(y_train)\n",
    "\n",
    "    return X_train_combined, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_validation_df(df):\n",
    "    seller_name = df['seller_item_name'].apply(str)\n",
    "    X_test_text = word_preprocessing(seller_name)\n",
    "    X_test_text = cv.transform(X_test_text).toarray()  \n",
    "\n",
    "    X_test_price = df[['price']].values  \n",
    "    X_test_price = StandardScaler().fit_transform(X_test_price)  \n",
    "\n",
    "    X_test_combined = np.hstack([X_test_text, X_test_price])  \n",
    "\n",
    "    y_test = df['sku'].values\n",
    "    y_test = le.transform(y_test)\n",
    "\n",
    "    return X_test_combined, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_test_df(df):\n",
    "    seller_name = df['seller_item_name'].apply(str)\n",
    "    X_test_text = word_preprocessing(seller_name)\n",
    "    X_test_text = cv.transform(X_test_text).toarray()  \n",
    "\n",
    "    X_test_price = df[['price']].values  \n",
    "    X_test_price = StandardScaler().fit_transform(X_test_price)  \n",
    "\n",
    "    X_test_combined = np.hstack([X_test_text, X_test_price])  \n",
    "\n",
    "\n",
    "    return X_test_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preparing_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "X_validat, y_validat  = preparing_validation_df(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "X_test = preparing_test_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66849"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.5197 - loss: 3.8148 - val_accuracy: 0.9587 - val_loss: 1.0131 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9682 - loss: 0.3400 - val_accuracy: 0.9773 - val_loss: 0.1610 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9820 - loss: 0.1713 - val_accuracy: 0.9817 - val_loss: 0.1360 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9868 - loss: 0.1277 - val_accuracy: 0.9837 - val_loss: 0.1310 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9888 - loss: 0.1086 - val_accuracy: 0.9846 - val_loss: 0.1186 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0957 - val_accuracy: 0.9886 - val_loss: 0.1074 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9916 - loss: 0.0858 - val_accuracy: 0.9874 - val_loss: 0.1033 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9920 - loss: 0.0793 - val_accuracy: 0.9869 - val_loss: 0.1032 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.9921 - loss: 0.0766 - val_accuracy: 0.9887 - val_loss: 0.0950 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9927 - loss: 0.0735 - val_accuracy: 0.9883 - val_loss: 0.0975 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9926 - loss: 0.0742 - val_accuracy: 0.9896 - val_loss: 0.0907 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9932 - loss: 0.0689 - val_accuracy: 0.9890 - val_loss: 0.0917 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9924 - loss: 0.0678 - val_accuracy: 0.9889 - val_loss: 0.0942 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9928 - loss: 0.0698\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9928 - loss: 0.0698 - val_accuracy: 0.9895 - val_loss: 0.0944 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9943 - loss: 0.0624 - val_accuracy: 0.9896 - val_loss: 0.0873 - learning_rate: 2.5000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9961 - loss: 0.0528 - val_accuracy: 0.9893 - val_loss: 0.0840 - learning_rate: 2.5000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9961 - loss: 0.0477 - val_accuracy: 0.9898 - val_loss: 0.0794 - learning_rate: 2.5000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9955 - loss: 0.0456 - val_accuracy: 0.9896 - val_loss: 0.0767 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9953 - loss: 0.0462 - val_accuracy: 0.9892 - val_loss: 0.0774 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9951 - loss: 0.0425 - val_accuracy: 0.9903 - val_loss: 0.0722 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9957 - loss: 0.0407 - val_accuracy: 0.9897 - val_loss: 0.0740 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9957 - loss: 0.0400 - val_accuracy: 0.9905 - val_loss: 0.0744 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9948 - loss: 0.0382 - val_accuracy: 0.9902 - val_loss: 0.0703 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9958 - loss: 0.0358 - val_accuracy: 0.9898 - val_loss: 0.0726 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9957 - loss: 0.0367 - val_accuracy: 0.9902 - val_loss: 0.0693 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9963 - loss: 0.0340 - val_accuracy: 0.9899 - val_loss: 0.0717 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9954 - loss: 0.0360 - val_accuracy: 0.9896 - val_loss: 0.0696 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m521/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0337\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0337 - val_accuracy: 0.9893 - val_loss: 0.0701 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9965 - loss: 0.0316 - val_accuracy: 0.9907 - val_loss: 0.0652 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9963 - loss: 0.0295 - val_accuracy: 0.9902 - val_loss: 0.0655 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9964 - loss: 0.0275 - val_accuracy: 0.9907 - val_loss: 0.0629 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9966 - loss: 0.0260 - val_accuracy: 0.9911 - val_loss: 0.0632 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0252 - val_accuracy: 0.9912 - val_loss: 0.0621 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9967 - loss: 0.0242 - val_accuracy: 0.9911 - val_loss: 0.0596 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9967 - loss: 0.0244 - val_accuracy: 0.9910 - val_loss: 0.0583 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9961 - loss: 0.0245 - val_accuracy: 0.9910 - val_loss: 0.0587 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9965 - loss: 0.0243 - val_accuracy: 0.9911 - val_loss: 0.0590 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9965 - loss: 0.0228 - val_accuracy: 0.9905 - val_loss: 0.0577 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9970 - loss: 0.0211 - val_accuracy: 0.9906 - val_loss: 0.0579 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9966 - loss: 0.0217 - val_accuracy: 0.9905 - val_loss: 0.0589 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0203\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0203 - val_accuracy: 0.9904 - val_loss: 0.0590 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0207 - val_accuracy: 0.9911 - val_loss: 0.0560 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0190 - val_accuracy: 0.9910 - val_loss: 0.0560 - learning_rate: 6.2500e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0183 - val_accuracy: 0.9910 - val_loss: 0.0550 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9971 - loss: 0.0183 - val_accuracy: 0.9912 - val_loss: 0.0553 - learning_rate: 6.2500e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9970 - loss: 0.0184 - val_accuracy: 0.9907 - val_loss: 0.0566 - learning_rate: 6.2500e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0171 - val_accuracy: 0.9907 - val_loss: 0.0539 - learning_rate: 6.2500e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 30ms/step - accuracy: 0.9968 - loss: 0.0170 - val_accuracy: 0.9909 - val_loss: 0.0542 - learning_rate: 6.2500e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9968 - loss: 0.0175 - val_accuracy: 0.9916 - val_loss: 0.0535 - learning_rate: 6.2500e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0173 - val_accuracy: 0.9907 - val_loss: 0.0535 - learning_rate: 6.2500e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9966 - loss: 0.0166 - val_accuracy: 0.9911 - val_loss: 0.0531 - learning_rate: 6.2500e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0152 - val_accuracy: 0.9913 - val_loss: 0.0536 - learning_rate: 6.2500e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9969 - loss: 0.0163 - val_accuracy: 0.9912 - val_loss: 0.0536 - learning_rate: 6.2500e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0160 - val_accuracy: 0.9920 - val_loss: 0.0520 - learning_rate: 6.2500e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9971 - loss: 0.0156 - val_accuracy: 0.9910 - val_loss: 0.0531 - learning_rate: 6.2500e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0147 - val_accuracy: 0.9916 - val_loss: 0.0527 - learning_rate: 6.2500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0148\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9971 - loss: 0.0148 - val_accuracy: 0.9913 - val_loss: 0.0532 - learning_rate: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0141 - val_accuracy: 0.9917 - val_loss: 0.0518 - learning_rate: 3.1250e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0139 - val_accuracy: 0.9908 - val_loss: 0.0524 - learning_rate: 3.1250e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0133 - val_accuracy: 0.9913 - val_loss: 0.0517 - learning_rate: 3.1250e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0138 - val_accuracy: 0.9910 - val_loss: 0.0510 - learning_rate: 3.1250e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9970 - loss: 0.0139 - val_accuracy: 0.9917 - val_loss: 0.0515 - learning_rate: 3.1250e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9973 - loss: 0.0129 - val_accuracy: 0.9918 - val_loss: 0.0510 - learning_rate: 3.1250e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m521/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0130\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.9975 - loss: 0.0130 - val_accuracy: 0.9911 - val_loss: 0.0513 - learning_rate: 3.1250e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9977 - loss: 0.0124 - val_accuracy: 0.9911 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0128 - val_accuracy: 0.9908 - val_loss: 0.0526 - learning_rate: 1.5625e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0123\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.9977 - loss: 0.0123 - val_accuracy: 0.9916 - val_loss: 0.0523 - learning_rate: 1.5625e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9972 - loss: 0.0132 - val_accuracy: 0.9913 - val_loss: 0.0522 - learning_rate: 7.8125e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0124 - val_accuracy: 0.9911 - val_loss: 0.0520 - learning_rate: 7.8125e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m522/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0125\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0125 - val_accuracy: 0.9909 - val_loss: 0.0521 - learning_rate: 7.8125e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3014d1400>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "num_classes = len(set(y_train))  \n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001), input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.01)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_validat, y_validat), callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0117\n",
      "Train Accuracy: 0.9979\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0515\n",
      "validate Accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "validation_loss, validation_acc = model.evaluate(X_validat, y_validat)\n",
    "print(f\"validate Accuracy: {validation_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2090/2090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1312</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4743</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2517</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2374</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>639</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Confidence\n",
       "0      1312       1.00\n",
       "1      4743       1.00\n",
       "2      2517       1.00\n",
       "3      2374       1.00\n",
       "4       639       1.00"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = model.predict(X_test)\n",
    "\n",
    "confidence_scores = np.max(probabilities, axis=1)\n",
    "\n",
    "predicted_indices = np.argmax(probabilities, axis=1)\n",
    "\n",
    "predicted_labels = le.inverse_transform(predicted_indices)\n",
    "\n",
    "confidence_threshold = 0.85\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    confidence = confidence_scores[i]\n",
    "    predicted_class = predicted_labels[i]\n",
    "\n",
    "    if confidence < confidence_threshold:\n",
    "        predicted_class = \"Unknown\"\n",
    "\n",
    "    test_results.append({\n",
    "        'Predicted': predicted_class,\n",
    "        'Confidence': f\"{confidence:.2f}\"\n",
    "    })\n",
    "\n",
    "temp_df = pd.DataFrame(test_results)\n",
    "\n",
    "temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_item_name</th>\n",
       "      <th>price</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>موزابرايد 5 مجم ق 3 ش/ويسترن</td>\n",
       "      <td>91.5</td>\n",
       "      <td>1312</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ميكروسرك 16 اقراص</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4743</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>البافيت كالسيوم شراب</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>زيستريل 20 مجم اقراص</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2374</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اتور 10مجم اقراص</td>\n",
       "      <td>33.0</td>\n",
       "      <td>639</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               seller_item_name  price Predicted Confidence\n",
       "0  موزابرايد 5 مجم ق 3 ش/ويسترن   91.5      1312       1.00\n",
       "1             ميكروسرك 16 اقراص   29.0      4743       1.00\n",
       "2         البافيت كالسيوم شراب    26.0      2517       1.00\n",
       "3         زيستريل 20 مجم اقراص    52.0      2374       1.00\n",
       "4              اتور 10مجم اقراص   33.0       639       1.00"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df['Predicted'] = temp_df['Predicted'].values\n",
    "predicted_df['Confidence'] = temp_df['Confidence'].values\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.to_csv('predicted.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
